{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from main.ipynb\n",
      "importing Jupyter notebook from loaddataset.ipynb\n",
      "importing Jupyter notebook from preprocessing.ipynb\n",
      "WARNING:tensorflow:From <string>:10: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "/home/unknown-user/Desktop/TensorFlow-NeuralNetwork/Dataset/french horn/french-horn_Cs4_1_fortissimo_normal.mp3\n",
      "[[0.00150795 0.00129682 0.001295   0.00351965 0.00285854 0.01071047\n",
      "  0.02025729 0.05037732 0.1142092  0.03677604 0.03314852 0.02410314\n",
      "  0.01675234 0.01393116 0.00950395 0.00967498 0.01127058 0.01371077\n",
      "  0.01523237 0.0223539  0.03503926 0.27178463 0.8806972  0.03794649\n",
      "  0.02154926 0.0167404  0.01377652 0.01167539 0.0108272  0.00971499\n",
      "  0.01044895 0.00912147 0.00976742 0.01267971 0.01823072 0.1482253\n",
      "  0.3125389  0.01224954 0.00596997 0.00409397 0.00316089 0.00306482\n",
      "  0.00194023 0.00183161 0.00242005 0.00185074 0.00185225 0.005525\n",
      "  0.00966326 0.06990954]]\n",
      "(1, 50)\n",
      "WARNING:tensorflow:From /home/unknown-user/.local/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from trainedmodel/model.ckpt\n",
      "This is violin\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.model_selection as skmodel\n",
    "import seaborn as sns\n",
    "import time\n",
    "import import_ipynb\n",
    "from main import randomfile\n",
    "from preprocessing import audioToVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['banjo', 'cello', 'clarinet', 'french horn', 'guitar', 'oboe', 'trumpet', 'violin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1520, 50) (1520,)\n",
      "\n",
      " (1520, 8) \n",
      " [[3.23017733e-02 4.64828580e-02 1.11054201e-01 1.70046359e-01\n",
      "  7.16463135e-01 8.38322927e-02 1.57624123e-02 6.91913874e-03\n",
      "  1.46402297e-02 1.28017711e-02 1.47205465e-02 1.40448302e-02\n",
      "  2.55979590e-02 2.66469831e-02 3.47189786e-02 2.37315204e-02\n",
      "  3.89080574e-02 7.71439174e-02 8.54687566e-02 1.18662916e-01\n",
      "  1.70851403e-01 9.08870648e-01 1.00000000e+00 1.32222887e-01\n",
      "  4.39310904e-02 1.50710482e-02 0.00000000e+00 2.45607589e-04\n",
      "  2.12088998e-03 4.56738572e-03 1.53353131e-02 2.60505989e-02\n",
      "  2.26926610e-02 5.61105999e-03 3.61079561e-02 5.31209161e-02\n",
      "  1.03896930e-01 1.73303738e-01 2.35484069e-01 3.31974735e-01\n",
      "  1.58067446e-01 1.28280515e-01 8.22950353e-02 7.90350772e-02\n",
      "  3.40177365e-02 1.23830580e-02 4.25610303e-03 1.37617876e-03\n",
      "  2.97635283e-03 1.93849732e-03]\n",
      " [1.11631140e-01 1.39826538e-01 2.03712812e-01 1.00000000e+00\n",
      "  1.20991972e-01 7.80495026e-04 8.86429591e-03 1.99968404e-02\n",
      "  2.39934084e-02 2.35271566e-02 3.25754950e-02 6.42559203e-02\n",
      "  8.53763331e-02 2.82885154e-02 5.29682730e-02 7.06217081e-02\n",
      "  6.37473303e-02 1.02753023e-01 1.09281820e-01 1.53251425e-01\n",
      "  2.78965898e-01 9.25109842e-01 8.86680203e-01 1.21102820e-01\n",
      "  3.53827704e-02 1.48742582e-02 2.79974647e-03 9.44690740e-03\n",
      "  2.53183004e-02 3.55982038e-02 2.14197084e-02 5.01359985e-03\n",
      "  4.11684497e-02 6.21378612e-02 1.04069609e-01 1.14059534e-01\n",
      "  9.04172345e-02 3.02132472e-02 1.07734298e-01 2.68261550e-01\n",
      "  4.94350672e-01 3.25632691e-01 7.20156083e-02 3.91163668e-02\n",
      "  3.51819218e-02 2.44275394e-02 7.60737844e-03 5.67926572e-03\n",
      "  1.00546274e-03 0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "#Preparing Training and Testing data\n",
    "Xdata = pd.read_csv('features.csv', header = None)\n",
    "Ydata = pd.read_csv('lables.csv', header = None)\n",
    "X1 = Xdata.values[:,:]\n",
    "Y = Ydata.values[:,0]\n",
    "print(X1.shape,Y.shape)\n",
    "'''X1 = tf.keras.utils.normalize(\n",
    "    X1,\n",
    "    axis=0,\n",
    "    order=2\n",
    ")'''\n",
    "for i in range(1520):\n",
    "    X1[i] = ( X1[i] - min(X1[i]) ) /( max(X1[i]) - min(X1[i]) )\n",
    "\n",
    "def one_hot_matrix(labels, C):\n",
    "    \"\"\"\n",
    "    Creates a matrix where the i-th row corresponds to the ith class number and the jth column\n",
    "                     corresponds to the jth training example. So if example j had a label i. Then entry (i,j) \n",
    "                     will be 1. \n",
    "                     \n",
    "    Arguments:\n",
    "    labels -- vector containing the labels \n",
    "    C -- number of classes, the depth of the one hot dimension\n",
    "    \n",
    "    Returns: \n",
    "    one_hot -- one hot matrix\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    \n",
    "    # Create a tf.constant equal to C (depth), name it 'C'. (approx. 1 line)\n",
    "    C = tf.constant(C, name= 'C')\n",
    "    \n",
    "    # Use tf.one_hot, be careful with the axis (approx. 1 line)\n",
    "    one_hot_matrix = tf.one_hot(labels,C,axis=1)\n",
    "    \n",
    "    # Create the session (approx. 1 line)\n",
    "    sess = tf.Session()\n",
    "    \n",
    "    # Run the session (approx. 1 line)\n",
    "    one_hot = sess.run(one_hot_matrix)\n",
    "    \n",
    "    # Close the session (approx. 1 line). See method 1 above.\n",
    "    sess.close()\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return one_hot\n",
    "Y = one_hot_matrix(Y, C=8)\n",
    "print('\\n',Y.shape,'\\n',X1[:2])\n",
    "X_train, X_test, Y_train, Y_test = skmodel.train_test_split(X1,Y, test_size=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 8\n",
    "X = tf.placeholder('float', [None, len(X_train[0])])\n",
    "y = tf.placeholder('float')\n",
    "\n",
    "n_nodes_hl1 = 90\n",
    "batch_size = 30\n",
    "display_step = 100\n",
    "keep_prob = tf.placeholder(\"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(data):\n",
    "\n",
    "    hidden_1_layer = {'weights':tf.Variable(tf.random_normal([X_train.shape[1], n_nodes_hl1])),\n",
    "                      'biases':tf.Variable(tf.random_normal([n_nodes_hl1]))}\n",
    "\n",
    "    output_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_hl1, n_classes])),\n",
    "                      'biases':tf.Variable(tf.random_normal([n_classes]))}\n",
    "    \n",
    "    # (input_data * weights) + biases\n",
    "\n",
    "    l1 = tf.add(tf.matmul(data, hidden_1_layer['weights']), hidden_1_layer['biases'])\n",
    "    l1 = tf.nn.sigmoid(l1)\n",
    "    l1 = tf.nn.dropout(l1, keep_prob)\n",
    "    output = tf.matmul(l1, output_layer['weights']) + output_layer['biases']\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning Training \n",
      "\n",
      "Epoch: 0001 cost= 5.195633427\n",
      "Accuracy: 0.29605263\n",
      "Epoch: 0101 cost= 0.704216452\n",
      "Accuracy: 0.70394737\n",
      "Epoch: 0201 cost= 0.423126283\n",
      "Accuracy: 0.7631579\n",
      "Epoch: 0301 cost= 0.316910470\n",
      "Accuracy: 0.7894737\n",
      "Epoch: 0401 cost= 0.232745515\n",
      "Accuracy: 0.82236844\n",
      "Epoch: 0501 cost= 0.189950833\n",
      "Accuracy: 0.80263156\n",
      "Epoch: 0601 cost= 0.169973509\n",
      "Accuracy: 0.80921054\n",
      "Optimization Finished!\n",
      "Accuracy: 0.78289473\n",
      "/home/unknown-user/Desktop/TensorFlow-NeuralNetwork/Dataset/oboe/oboe_Fs4_15_fortissimo_normal.mp3\n",
      "0.28698015 141.41173\n",
      "[[1.13036539e-02 2.07302961e-02 5.63814342e-02 9.21959519e-01\n",
      "  1.03458211e-01 3.12634185e-02 2.28585079e-02 1.70752816e-02\n",
      "  1.51894409e-02 1.34636946e-02 1.30102839e-02 1.24388961e-02\n",
      "  1.22382855e-02 1.27476584e-02 1.29645364e-02 1.44713763e-02\n",
      "  1.59844216e-02 1.76666901e-02 2.27364711e-02 2.82297414e-02\n",
      "  5.05608842e-02 6.27443612e-01 1.00000000e+00 4.68710884e-02\n",
      "  2.41688192e-02 1.31818354e-02 7.65983993e-03 6.05966011e-03\n",
      "  3.14541324e-03 1.98173756e-03 3.27510876e-04 0.00000000e+00\n",
      "  8.45274597e-04 1.65078370e-03 2.14056321e-03 5.20995446e-03\n",
      "  8.62150360e-03 1.34641537e-02 2.53546499e-02 8.37248042e-02\n",
      "  8.47829044e-01 1.26458034e-01 3.02300826e-02 1.93288531e-02\n",
      "  1.39455618e-02 1.09506575e-02 9.17801820e-03 8.44176114e-03\n",
      "  7.29082385e-03 6.80886349e-03]]\n",
      "This is oboe\n"
     ]
    }
   ],
   "source": [
    "def train(x):\n",
    "\n",
    "    pred = model(x)\n",
    "    #loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(pred, y))\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "    optimizer = tf.train.AdamOptimizer(0.007).minimize(loss)\n",
    "\n",
    "    epochs = 700\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.initialize_all_variables())\n",
    "        print ('Beginning Training \\n')\n",
    "        for epoch in range(epochs):\n",
    "            avg_cost = 0.0\n",
    "            total_batch = int(len(X_train) / batch_size)\n",
    "            x_batches = np.array_split(X_train, total_batch)\n",
    "            y_batches = np.array_split(Y_train, total_batch)\n",
    "            for i in range(total_batch):\n",
    "                batch_x, batch_y = x_batches[i], y_batches[i]\n",
    "                _, c = sess.run([optimizer, loss], \n",
    "                                feed_dict={\n",
    "                                    x: batch_x, \n",
    "                                    y: batch_y, \n",
    "                                    keep_prob: 0.8\n",
    "                                })\n",
    "                avg_cost += c / total_batch\n",
    "            if epoch % display_step == 0:\n",
    "                print(\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \\\n",
    "                    \"{:.9f}\".format(avg_cost))\n",
    "\n",
    "                correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "                accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "                print(\"Accuracy:\", accuracy.eval({x: X_test, y: Y_test, keep_prob: 1.0}))\n",
    "        print(\"Optimization Finished!\")\n",
    "        \n",
    "        \n",
    "        correct = tf.equal(tf.arg_max(pred, 1), tf.arg_max(y, 1))\n",
    "        acc = tf.reduce_mean(tf.cast(correct, 'float'))\n",
    "        print(\"Accuracy:\", acc.eval({x:X_test, y:Y_test, keep_prob: 1.0}))\n",
    "#         global X1\n",
    "#         predictions = pred.eval(feed_dict = {x:X1[:24], keep_prob: 1.0})\n",
    "#         print(predictions.argmax(axis=1)[:24])\n",
    "        \n",
    "        \n",
    "        path = randomfile('/home/unknown-user/Desktop/TensorFlow-NeuralNetwork/Dataset/')\n",
    "        print(path)\n",
    "        xtemp = audioToVector(path)\n",
    "        X1 = np.array(xtemp)[np.newaxis,:]\n",
    "        '''X1 = tf.keras.utils.normalize(\n",
    "                X1,\n",
    "                axis=-1,\n",
    "                order=2\n",
    "            )'''\n",
    "        print(min(X1[0]), max(X1[0]))\n",
    "        X1 = ( X1 - min(X1[0]) ) /( max(X1[0]) - min(X1[0]) )\n",
    "        print(X1)\n",
    "        predictions = pred.eval(feed_dict = {x:X1, keep_prob: 1 })\n",
    "                                                    #keep_prob is deprecated and will be removed in a future version\n",
    "        print('This is',class_names[int(predictions.argmax(axis=1))] )\n",
    "        \n",
    "\n",
    "train(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
